{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"vinai/vinai-translate-vi2en\", src_lang=\"vi_VN\")\n",
    "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/vinai-translate-vi2en\")\n",
    "device_vi2en = torch.device(\"cuda\")\n",
    "model_vi2en.to(device_vi2en)\n",
    "\n",
    "\n",
    "def translate_vi2en(vi_texts: str) -> str:\n",
    "    try:\n",
    "        input_ids = tokenizer_vi2en(vi_texts, padding=True, return_tensors=\"pt\").to(device_vi2en)\n",
    "        output_ids = model_vi2en.generate(\n",
    "            **input_ids,\n",
    "            decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
    "            num_return_sequences=1,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        en_texts = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        return en_texts\n",
    "    except: \n",
    "        # print full error\n",
    "        print(\"Error: \", sys.exc_info()[0])\n",
    "        # print trace back\n",
    "        print(traceback.format_exc())\n",
    "        # print error line\n",
    "        print(\"Error: \", vi_texts)\n",
    "\n",
    "# # The input may consist of multiple text sequences, with the number of text sequences in the input ranging from 1 up to 8, 16, 32, or even higher, depending on the GPU memory.\n",
    "# vi_texts = [\"Cô cho biết: trước giờ tôi không đến phòng tập công cộng, mà tập cùng giáo viên Yoga riêng hoặc tự tập ở nhà.\",\n",
    "#             \"Khi tập thể dục trong không gian riêng tư, tôi thoải mái dễ chịu hơn.\",\n",
    "#             \"cô cho biết trước giờ tôi không đến phòng tập công cộng mà tập cùng giáo viên yoga riêng hoặc tự tập ở nhà khi tập thể dục trong không gian riêng tư tôi thoải mái dễ chịu hơn\"]\n",
    "# print(translate_vi2en(vi_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn3k = pd.read_json('/home/phongtnh/Person-Search/vn3k.json')\n",
    "vn3k = vn3k[['file_path', 'captions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6302 [00:00<?, ?it/s]/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (1024) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 112/6302 [00:50<34:36,  2.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  <class 'IndexError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3106436/2079250303.py\", line 12, in translate_vi2en\n",
      "    input_ids = tokenizer_vi2en(vi_texts, padding=True, return_tensors=\"pt\").to(device_vi2en)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2577, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2663, in _call_one\n",
      "    return self.batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2854, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/phongtnh/miniconda3/envs/person_search/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 458, in _batch_encode_plus\n",
      "    for key in tokens_and_encodings[0][0].keys():\n",
      "               ~~~~~~~~~~~~~~~~~~~~^^^\n",
      "IndexError: list index out of range\n",
      "\n",
      "Error:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6302/6302 [42:18<00:00,  2.48it/s]  \n"
     ]
    }
   ],
   "source": [
    "# tracking progression using tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "vn3k['vi_captions'] = vn3k['captions'].progress_apply(translate_vi2en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn3k.to_csv('vn3k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn3k[['captions', 'vi_captions']].to_csv('vn3k_trans_review.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "person_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
